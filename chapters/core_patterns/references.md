## References

1. Fikes, R., Nilsson, N. *STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving*. Artificial Intelligence, 1971.
2. Newell, A., Simon, H. A. *Human Problem Solving*. Prentice-Hall, 1972.
3. Sacerdoti, E. *Planning in a Hierarchy of Abstraction Spaces*. Artificial Intelligence, 1974.
4. Sheridan, T. B., Verplank, W. L. *Human and Computer Control of Undersea Teleoperators*. MIT Man-Machine Systems Laboratory, 1978.
5. Nau, D. et al. *Hierarchical Task Network Planning*. AI Magazine, 2003.
6. Palatucci, M., Pomerleau, D., Hinton, G., Mitchell, T. *Zero-shot Learning with Semantic Output Codes*. NIPS, 2009.
7. Settles, B. *Active Learning Literature Survey*. University of Wisconsin-Madison, 2010.
8. Mikolov, T., Chen, K., Corrado, G., Dean, J. *Efficient Estimation of Word Representations in Vector Space*. arXiv, 2013.
9. Amershi, S. et al. *Human-in-the-Loop Machine Learning*. ACM CHI, 2014.
10. Radford, A., Wu, J., Child, R. et al. *Language Models are Unsupervised Multitask Learners*. OpenAI, 2019.
11. Russell, S. *Human-Compatible Artificial Intelligence*. AI Magazine, 2019.
12. Russell, S., Norvig, P. *Artificial Intelligence: A Modern Approach*. Pearson.
13. Brown, T. B., Mann, B., Ryder, N. et al. *Language Models are Few-Shot Learners*. NeurIPS, 2020.
14. Cobbe, K. et al. *Training Verifiers to Solve Math Word Problems*. arXiv, 2021. https://arxiv.org/abs/2110.14168
15. Nakano, R. et al. *WebGPT: Browser-assisted Question-answering with Human Feedback*. arXiv, 2021. https://arxiv.org/abs/2112.09332
16. Nye, M. et al. *Show Your Work: Scratchpads for Intermediate Computation with Language Models*. arXiv, 2021. https://arxiv.org/abs/2112.00114
17. Karpas, E. et al. *MRKL Systems: A Modular, Neuro-Symbolic Architecture that Combines Large Language Models, External Knowledge Sources and Discrete Reasoning*. arXiv, 2022. https://arxiv.org/abs/2205.00445
18. Kojima, T. et al. *Large Language Models are Zero-Shot Reasoners*. NeurIPS, 2022. https://arxiv.org/abs/2205.11916
19. Saunders, W. et al. *Self-Critique and the Limits of Model Introspection*. arXiv, 2022.
20. Wang, X. et al. *Self-Consistency Improves Chain of Thought Reasoning in Language Models*. arXiv, 2022.
21. Wei, J. et al. *Chain-of-Thought Prompting Elicits Reasoning in Large Language Models*. NeurIPS, 2022. https://arxiv.org/abs/2201.11903
22. Xie, S., Ma, X., Wang, Y. et al. *An Explanation of In-Context Learning as Implicit Bayesian Inference*. ICLR, 2022.
23. Yao, S. et al. *ReAct: Synergizing Reasoning and Acting in Language Models*. ICLR, 2023. https://arxiv.org/abs/2210.03629
24. Madaan, A. et al. *Self-Refine: Iterative Refinement with Self-Feedback*. arXiv, 2023.
25. Schick, T. et al. *Toolformer: Language Models Can Teach Themselves to Use Tools*. arXiv, 2023. https://arxiv.org/abs/2302.04761
26. Shinn, N. et al. *Reflexion: Language Agents with Verbal Reinforcement Learning*. NeurIPS, 2023.
27. Yao, S. et al. *Tree of Thoughts: Deliberate Problem Solving with Large Language Models*. arXiv, 2023. https://arxiv.org/abs/2305.10601
28. Zhou, D. et al. *Least-to-Most Prompting Enables Complex Reasoning in Large Language Models*. ICLR, 2023.
29. OpenAI. *Best Practices for Human-in-the-Loop AI Systems*. Technical blog, 2023.
