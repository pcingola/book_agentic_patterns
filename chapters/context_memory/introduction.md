## Introduction

As agents gain more tools, coordinate across multiple steps, and retrieve external documents, the amount of information competing for space in the context window grows rapidly. Every tool call adds input and output tokens. Every orchestration step extends the conversation history. Every retrieved chunk consumes context budget. Managing this information -- deciding what to include, what to compress, and what to discard -- becomes a first-class engineering concern.

The management of context in agentic systems began with "prompt engineering," a term that originally described the craft of writing effective instructions for language models. Early practitioners discovered that small changes in phrasing, example selection, and information ordering could dramatically affect model outputs. What started as informal experimentation with prompts evolved into a systematic discipline as context windows expanded and agents became more capable. Today, context management encompasses not just prompt design but also memory architectures, history compaction, token budgeting, and the orchestration of information flow across multi-turn interactions. This chapter traces that evolution and presents practical techniques for engineering context in production agentic systems.
