{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Workspace\n",
    "\n",
    "The workspace pattern provides a shared, persistent file system where agents externalize artifacts too large for the context window. Agents see sandbox paths (`/workspace/...`) while actual files are stored in isolated directories per user and session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nimport tempfile\nimport json\n\nfrom agentic_patterns.core.workspace import (\n    configure_workspace, DefaultIdentityExtractor,\n    container_to_host_path, write_to_workspace, read_from_workspace, list_workspace_files,\n)\nfrom agentic_patterns.core.agents import get_agent, run_agent"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Startup Configuration\n",
    "\n",
    "At server startup, configure the workspace with a base directory and an identity extractor. The identity extractor pulls user/session IDs from the HTTP request context (JWT claims, session cookies, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(tempfile.mkdtemp())\n",
    "\n",
    "# In production, implement IdentityExtractor to read from JWT/session\n",
    "identity_extractor = DefaultIdentityExtractor(user_id=\"alice\", session_id=\"session_001\")\n",
    "\n",
    "configure_workspace(WorkspaceConfig(\n",
    "    base_dir=base_dir,\n",
    "    identity_extractor=identity_extractor,\n",
    "))\n",
    "\n",
    "print(f\"Workspace base: {base_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Translation\n",
    "\n",
    "Tools receive `ctx` (the request context) from the framework. Helper functions convert between sandbox paths (what agents see) and host paths (actual filesystem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctx is passed by the framework - for demo we use None (DefaultIdentityExtractor ignores it)\n",
    "ctx = None\n",
    "\n",
    "sandbox_path = \"/workspace/reports/analysis.json\"\n",
    "host_path = container_to_host_path(sandbox_path, ctx)\n",
    "\n",
    "print(f\"Agent sees:    {sandbox_path}\")\n",
    "print(f\"Actual file:   {host_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Pattern: Write Large Output, Return Summary\n",
    "\n",
    "When a tool produces large output, it writes the full result to the workspace and returns a concise summary with the file path. The agent's context stays small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(query: str, ctx) -> str:\n",
    "    \"\"\"Analyze data and save results to workspace.\"\"\"\n",
    "    result = {\n",
    "        \"query\": query,\n",
    "        \"row_count\": 50000,\n",
    "        \"statistics\": {\"mean\": 42.5, \"std\": 12.3, \"min\": 0.1, \"max\": 99.8},\n",
    "        \"data\": [{\"id\": i, \"value\": i * 0.1} for i in range(1000)],\n",
    "    }\n",
    "    \n",
    "    output_path = \"/workspace/analysis/result.json\"\n",
    "    write_to_workspace(output_path, json.dumps(result, indent=2), ctx)\n",
    "    \n",
    "    return f\"\"\"Analysis complete. Rows: {result['row_count']}, Mean: {result['statistics']['mean']}\n",
    "Full results: {output_path}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = analyze_dataset(\"SELECT * FROM metrics\", ctx)\n",
    "print(summary)\n",
    "\n",
    "# Verify file exists on disk\n",
    "host_path = container_to_host_path(\"/workspace/analysis/result.json\", ctx)\n",
    "print(f\"\\nFile size: {host_path.stat().st_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent with Workspace Tools\n",
    "\n",
    "Tools receive `ctx` from the framework and use workspace helpers. The framework injects `ctx` automatically - tools just declare it as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_data(query: str, ctx) -> str:\n",
    "    \"\"\"Search dataset and save results to workspace.\"\"\"\n",
    "    matches = [{\"id\": i, \"name\": f\"item_{i}\", \"score\": 0.9 - i*0.01} for i in range(500)]\n",
    "    \n",
    "    output_path = \"/workspace/search_results.json\"\n",
    "    write_to_workspace(output_path, json.dumps(matches), ctx)\n",
    "    \n",
    "    return f\"Found {len(matches)} matches. Top 3: {matches[:3]}. Full results: {output_path}\"\n",
    "\n",
    "\n",
    "def read_file(path: str, ctx) -> str:\n",
    "    \"\"\"Read a file from the workspace.\"\"\"\n",
    "    return read_from_workspace(path, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = get_agent(tools=[search_data, read_file])\n",
    "\n",
    "prompt = \"Search for sensor data and tell me how many results were found.\"\n",
    "agent_run, nodes = await run_agent(agent, prompt, verbose=True)\n",
    "\n",
    "print(f\"\\nAnswer: {agent_run.result.output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data persists in workspace\n",
    "print(\"Files in workspace:\")\n",
    "for f in list_workspace_files(\"*.json\", ctx):\n",
    "    host_path = container_to_host_path(f, ctx)\n",
    "    print(f\"  {f} ({host_path.stat().st_size} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Isolation\n",
    "\n",
    "Each user/session gets an isolated directory. The identity extractor determines which workspace to use based on the request context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconfigure with different user\n",
    "configure_workspace(WorkspaceConfig(\n",
    "    base_dir=base_dir,\n",
    "    identity_extractor=DefaultIdentityExtractor(user_id=\"bob\", session_id=\"session_001\"),\n",
    "))\n",
    "\n",
    "write_to_workspace(\"/workspace/secret.txt\", \"Bob's private data\", ctx)\n",
    "\n",
    "# Bob's file is in a different directory\n",
    "bob_path = container_to_host_path(\"/workspace/secret.txt\", ctx)\n",
    "print(f\"Bob's file: {bob_path}\")\n",
    "print(f\"Alice's file would be: {base_dir}/alice/session_001/secret.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Security: Path Traversal Prevention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_patterns.core.workspace import WorkspaceError\n",
    "\n",
    "try:\n",
    "    container_to_host_path(\"/workspace/../../../etc/passwd\", ctx)\n",
    "except WorkspaceError as e:\n",
    "    print(f\"Blocked: {e}\")\n",
    "\n",
    "try:\n",
    "    container_to_host_path(\"/etc/passwd\", ctx)\n",
    "except WorkspaceError as e:\n",
    "    print(f\"Blocked: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}