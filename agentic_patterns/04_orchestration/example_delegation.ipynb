{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Agent Delegation\n",
    "\n",
    "Delegation is when an agent invokes another agent through a tool while maintaining control of the overall task. The parent agent decides when to delegate, receives the result, and incorporates it into its final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from agentic_patterns.core.agents import get_agent, run_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-scenario",
   "metadata": {},
   "source": [
    "## The Scenario\n",
    "\n",
    "A research assistant helps users explore topics. When it makes factual claims, it can delegate verification to a fact-checker specialist. The research agent stays in control, deciding when verification is needed and how to incorporate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-specialist",
   "metadata": {},
   "source": [
    "## The Specialist Agent\n",
    "\n",
    "The fact-checker is a focused agent that evaluates specific claims. It returns structured output indicating whether the claim is accurate and providing context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactCheckResult(BaseModel):\n",
    "    claim: str = Field(description=\"The claim that was checked\")\n",
    "    verdict: str = Field(description=\"accurate, inaccurate, or partially accurate\")\n",
    "    explanation: str = Field(description=\"Brief explanation of the verdict\")\n",
    "\n",
    "\n",
    "fact_checker = get_agent(\n",
    "    output_type=FactCheckResult,\n",
    "    system_prompt=\"\"\"You are a fact-checker. Evaluate claims for accuracy.\n",
    "Be precise and cite your reasoning. Focus only on verifiable facts.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-tool",
   "metadata": {},
   "source": [
    "## The Delegation Tool\n",
    "\n",
    "The tool wraps the specialist agent. When the parent agent calls this tool, it runs the fact-checker and returns the result. The `RunContext` provides access to usage tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delegation-tool",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fact_check(ctx: RunContext[None], claim: str) -> str:\n",
    "    \"\"\"Verify a factual claim by delegating to a fact-checking specialist.\"\"\"\n",
    "    print(f\"[Delegating to fact-checker] Claim: {claim}\")\n",
    "    \n",
    "    agent_run, _ = await run_agent(\n",
    "        fact_checker,\n",
    "        f\"Fact-check this claim: {claim}\"\n",
    "    )\n",
    "    result = agent_run.result.output\n",
    "    \n",
    "    # Propagate usage from the delegated agent to the parent\n",
    "    ctx.usage.incr(agent_run.result.usage())\n",
    "    \n",
    "    print(f\"[Fact-checker result] {result.verdict}: {result.explanation}\")\n",
    "    return f\"Verdict: {result.verdict}. {result.explanation}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-parent",
   "metadata": {},
   "source": [
    "## The Parent Agent\n",
    "\n",
    "The research assistant has access to the fact_check tool. It decides autonomously when to verify claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parent-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = get_agent(\n",
    "    tools=[fact_check],\n",
    "    system_prompt=\"\"\"You are a research assistant. Help users explore topics accurately.\n",
    "When you make specific factual claims that could be verified, use the fact_check tool.\n",
    "After fact-checking, incorporate the results into your response.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-run",
   "metadata": {},
   "source": [
    "## Running the Delegation\n",
    "\n",
    "When the research agent encounters a claim worth verifying, it calls the fact_check tool. The specialist runs, and the result flows back to the parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Tell me about the speed of light and its discovery. \n",
    "Please verify the key facts you mention.\"\"\"\n",
    "\n",
    "agent_run, _ = await run_agent(research_agent, prompt, verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\"*50)\n",
    "print(agent_run.result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-usage",
   "metadata": {},
   "source": [
    "## Unified Usage Tracking\n",
    "\n",
    "Because we called `ctx.usage.incr()` in the tool, the parent agent's usage includes tokens from the delegated agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = agent_run.result.usage()\n",
    "print(f\"Total tokens (including delegated calls): {usage.total_tokens}\")\n",
    "print(f\"  Request tokens: {usage.request_tokens}\")\n",
    "print(f\"  Response tokens: {usage.response_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60688b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_agentic_patterns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
