{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History Compaction\n",
    "\n",
    "Over many turns, conversation history accumulates. `HistoryCompactor` summarizes older exchanges when approaching context limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_patterns.core.agents import get_agent, run_agent\n",
    "from agentic_patterns.core.context.history import HistoryCompactor, CompactionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure with low thresholds for demonstration\n",
    "config = CompactionConfig(max_tokens=500, target_tokens=200)\n",
    "compactor = HistoryCompactor(config=config)\n",
    "\n",
    "print(f\"Compaction triggers at: {config.max_tokens} tokens\")\n",
    "print(f\"Targets reduction to: {config.target_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_messages(messages: list, indent: int = 4):\n",
    "    \"\"\"Display messages with content preview.\"\"\"\n",
    "    prefix = \" \" * indent\n",
    "    if not messages:\n",
    "        print(f\"{prefix}(empty)\")\n",
    "        return\n",
    "    for i, msg in enumerate(messages):\n",
    "        parts_info = []\n",
    "        for part in msg.parts:\n",
    "            part_type = type(part).__name__\n",
    "            if hasattr(part, \"content\"):\n",
    "                text = str(part.content).replace(\"\\n\", \" \")[:50]\n",
    "                parts_info.append(f\"{part_type}({text}...)\")\n",
    "            else:\n",
    "                parts_info.append(part_type)\n",
    "        print(f\"{prefix}[{i}] {type(msg).__name__}: {', '.join(parts_info)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture what was actually sent to the agent\n",
    "sent_to_agent = None\n",
    "compaction_result = None\n",
    "\n",
    "\n",
    "async def capturing_processor(messages):\n",
    "    \"\"\"Processor that captures the compacted history sent to agent.\"\"\"\n",
    "    global sent_to_agent, compaction_result\n",
    "    original_tokens = compactor.count_tokens(messages)\n",
    "    compacted = await compactor.compact(messages)\n",
    "    compacted_tokens = compactor.count_tokens(compacted)\n",
    "\n",
    "    sent_to_agent = compacted\n",
    "    if len(compacted) != len(messages):\n",
    "        compaction_result = {\n",
    "            \"original_msgs\": len(messages),\n",
    "            \"compacted_msgs\": len(compacted),\n",
    "            \"original_tokens\": original_tokens,\n",
    "            \"compacted_tokens\": compacted_tokens,\n",
    "        }\n",
    "    else:\n",
    "        compaction_result = None\n",
    "    return compacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_compaction = get_agent(\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    history_processors=[capturing_processor],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Explain what microservices architecture is.\",\n",
    "    \"What are the main benefits?\",\n",
    "    \"What are common challenges?\",\n",
    "    \"How does it compare to monolithic architecture?\",\n",
    "]\n",
    "\n",
    "message_history = None\n",
    "\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"TURN {i}: {prompt}\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "\n",
    "    result, _ = await run_agent(\n",
    "        agent_with_compaction, prompt, message_history=message_history\n",
    "    )\n",
    "\n",
    "    # 1. SENT TO AGENT (what was actually sent, after compaction)\n",
    "    if compaction_result:\n",
    "        print(\n",
    "            f\"\\n  *** COMPACTION: {compaction_result['original_msgs']} msgs ({compaction_result['original_tokens']} tokens) \"\n",
    "            f\"-> {compaction_result['compacted_msgs']} msgs ({compaction_result['compacted_tokens']} tokens) ***\"\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"\\n  SENT TO AGENT ({len(sent_to_agent)} messages, {compactor.count_tokens(sent_to_agent)} tokens):\"\n",
    "    )\n",
    "    show_messages(sent_to_agent)\n",
    "\n",
    "    # 2. NEW MESSAGES (response from this turn)\n",
    "    new_msgs = list(result.new_messages())\n",
    "    print(\n",
    "        f\"\\n  NEW MESSAGES ({len(new_msgs)} messages, {compactor.count_tokens(new_msgs)} tokens):\"\n",
    "    )\n",
    "    show_messages(new_msgs)\n",
    "\n",
    "    # 3. Accumulate to uncompressed history\n",
    "    if message_history is None:\n",
    "        message_history = new_msgs\n",
    "    else:\n",
    "        message_history = message_history + new_msgs\n",
    "\n",
    "    print(\n",
    "        f\"\\n  UNCOMPRESSED HISTORY ({len(message_history)} messages, {compactor.count_tokens(message_history)} tokens):\"\n",
    "    )\n",
    "    show_messages(message_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
