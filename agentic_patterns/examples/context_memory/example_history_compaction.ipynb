{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History Compaction\n",
    "\n",
    "Over many turns, conversation history accumulates. `HistoryCompactor` summarizes older exchanges when approaching context limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_patterns.core.agents import get_agent, run_agent\n",
    "from agentic_patterns.core.context.history import HistoryCompactor, CompactionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compaction triggers at: 500 tokens\n",
      "Targets reduction to: 200 tokens\n"
     ]
    }
   ],
   "source": [
    "# Configure with low thresholds for demonstration\n",
    "config = CompactionConfig(max_tokens=500, target_tokens=200)\n",
    "compactor = HistoryCompactor(config=config)\n",
    "\n",
    "print(f\"Compaction triggers at: {config.max_tokens} tokens\")\n",
    "print(f\"Targets reduction to: {config.target_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_messages(messages: list, indent: int = 4):\n",
    "    \"\"\"Display messages with content preview.\"\"\"\n",
    "    prefix = \" \" * indent\n",
    "    if not messages:\n",
    "        print(f\"{prefix}(empty)\")\n",
    "        return\n",
    "    for i, msg in enumerate(messages):\n",
    "        parts_info = []\n",
    "        for part in msg.parts:\n",
    "            part_type = type(part).__name__\n",
    "            if hasattr(part, 'content'):\n",
    "                text = str(part.content).replace('\\n', ' ')[:50]\n",
    "                parts_info.append(f\"{part_type}({text}...)\")\n",
    "            else:\n",
    "                parts_info.append(part_type)\n",
    "        print(f\"{prefix}[{i}] {type(msg).__name__}: {', '.join(parts_info)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture what was actually sent to the agent\n",
    "sent_to_agent = None\n",
    "compaction_result = None\n",
    "\n",
    "async def capturing_processor(messages):\n",
    "    \"\"\"Processor that captures the compacted history sent to agent.\"\"\"\n",
    "    global sent_to_agent, compaction_result\n",
    "    original_tokens = compactor.count_tokens(messages)\n",
    "    compacted = await compactor.compact(messages)\n",
    "    compacted_tokens = compactor.count_tokens(compacted)\n",
    "    \n",
    "    sent_to_agent = compacted\n",
    "    if len(compacted) != len(messages):\n",
    "        compaction_result = {\n",
    "            \"original_msgs\": len(messages),\n",
    "            \"compacted_msgs\": len(compacted),\n",
    "            \"original_tokens\": original_tokens,\n",
    "            \"compacted_tokens\": compacted_tokens,\n",
    "        }\n",
    "    else:\n",
    "        compaction_result = None\n",
    "    return compacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_compaction = get_agent(\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    history_processors=[capturing_processor]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TURN 1: Explain what microservices architecture is.\n",
      "======================================================================\n",
      "\n",
      "  SENT TO AGENT (1 messages, 94 tokens):\n",
      "    [0] ModelRequest: SystemPromptPart(You are a helpful assistant....), UserPromptPart(Explain what microservices architecture is....)\n",
      "\n",
      "  NEW MESSAGES (2 messages, 467 tokens):\n",
      "    [0] ModelRequest: SystemPromptPart(You are a helpful assistant....), UserPromptPart(Explain what microservices architecture is....)\n",
      "    [1] ModelResponse: TextPart(# Microservices Architecture  **Microservices arch...)\n",
      "\n",
      "  UNCOMPRESSED HISTORY (2 messages, 467 tokens):\n",
      "    [0] ModelRequest: SystemPromptPart(You are a helpful assistant....), UserPromptPart(Explain what microservices architecture is....)\n",
      "    [1] ModelResponse: TextPart(# Microservices Architecture  **Microservices arch...)\n",
      "\n",
      "======================================================================\n",
      "TURN 2: What are the main benefits?\n",
      "======================================================================\n",
      "\n",
      "  *** COMPACTION: 3 msgs (510 tokens) -> 2 msgs (267 tokens) ***\n",
      "\n",
      "  SENT TO AGENT (2 messages, 267 tokens):\n",
      "    [0] ModelRequest: UserPromptPart(This session is being continued from a previous co...)\n",
      "    [1] ModelRequest: UserPromptPart(What are the main benefits?...)\n",
      "\n",
      "  NEW MESSAGES (2 messages, 390 tokens):\n",
      "    [0] ModelRequest: UserPromptPart(What are the main benefits?...)\n",
      "    [1] ModelResponse: TextPart(Based on our previous discussion, here are the mai...)\n",
      "\n",
      "  UNCOMPRESSED HISTORY (4 messages, 857 tokens):\n",
      "    [0] ModelRequest: SystemPromptPart(You are a helpful assistant....), UserPromptPart(Explain what microservices architecture is....)\n",
      "    [1] ModelResponse: TextPart(# Microservices Architecture  **Microservices arch...)\n",
      "    [2] ModelRequest: UserPromptPart(What are the main benefits?...)\n",
      "    [3] ModelResponse: TextPart(Based on our previous discussion, here are the mai...)\n",
      "\n",
      "======================================================================\n",
      "TURN 3: What are common challenges?\n",
      "======================================================================\n",
      "\n",
      "  *** COMPACTION: 5 msgs (899 tokens) -> 2 msgs (360 tokens) ***\n",
      "\n",
      "  SENT TO AGENT (2 messages, 360 tokens):\n",
      "    [0] ModelRequest: UserPromptPart(This session is being continued from a previous co...)\n",
      "    [1] ModelRequest: UserPromptPart(What are common challenges?...)\n",
      "\n",
      "  NEW MESSAGES (2 messages, 447 tokens):\n",
      "    [0] ModelRequest: UserPromptPart(What are common challenges?...)\n",
      "    [1] ModelResponse: TextPart(# Common Challenges in Microservices Architecture ...)\n",
      "\n",
      "  UNCOMPRESSED HISTORY (6 messages, 1304 tokens):\n",
      "    [0] ModelRequest: SystemPromptPart(You are a helpful assistant....), UserPromptPart(Explain what microservices architecture is....)\n",
      "    [1] ModelResponse: TextPart(# Microservices Architecture  **Microservices arch...)\n",
      "    [2] ModelRequest: UserPromptPart(What are the main benefits?...)\n",
      "    [3] ModelResponse: TextPart(Based on our previous discussion, here are the mai...)\n",
      "    [4] ModelRequest: UserPromptPart(What are common challenges?...)\n",
      "    [5] ModelResponse: TextPart(# Common Challenges in Microservices Architecture ...)\n",
      "\n",
      "======================================================================\n",
      "TURN 4: How does it compare to monolithic architecture?\n",
      "======================================================================\n",
      "\n",
      "  *** COMPACTION: 7 msgs (1350 tokens) -> 2 msgs (373 tokens) ***\n",
      "\n",
      "  SENT TO AGENT (2 messages, 373 tokens):\n",
      "    [0] ModelRequest: UserPromptPart(This session is being continued from a previous co...)\n",
      "    [1] ModelRequest: UserPromptPart(How does it compare to monolithic architecture?...)\n",
      "\n",
      "  NEW MESSAGES (2 messages, 989 tokens):\n",
      "    [0] ModelRequest: UserPromptPart(How does it compare to monolithic architecture?...)\n",
      "    [1] ModelResponse: TextPart(# Microservices vs Monolithic Architecture: A Deta...)\n",
      "\n",
      "  UNCOMPRESSED HISTORY (8 messages, 2293 tokens):\n",
      "    [0] ModelRequest: SystemPromptPart(You are a helpful assistant....), UserPromptPart(Explain what microservices architecture is....)\n",
      "    [1] ModelResponse: TextPart(# Microservices Architecture  **Microservices arch...)\n",
      "    [2] ModelRequest: UserPromptPart(What are the main benefits?...)\n",
      "    [3] ModelResponse: TextPart(Based on our previous discussion, here are the mai...)\n",
      "    [4] ModelRequest: UserPromptPart(What are common challenges?...)\n",
      "    [5] ModelResponse: TextPart(# Common Challenges in Microservices Architecture ...)\n",
      "    [6] ModelRequest: UserPromptPart(How does it compare to monolithic architecture?...)\n",
      "    [7] ModelResponse: TextPart(# Microservices vs Monolithic Architecture: A Deta...)\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Explain what microservices architecture is.\",\n",
    "    \"What are the main benefits?\",\n",
    "    \"What are common challenges?\",\n",
    "    \"How does it compare to monolithic architecture?\",\n",
    "]\n",
    "\n",
    "message_history = None\n",
    "\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TURN {i}: {prompt}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    result, _ = await run_agent(agent_with_compaction, prompt, message_history=message_history)\n",
    "    \n",
    "    # 1. SENT TO AGENT (what was actually sent, after compaction)\n",
    "    if compaction_result:\n",
    "        print(f\"\\n  *** COMPACTION: {compaction_result['original_msgs']} msgs ({compaction_result['original_tokens']} tokens) \"\n",
    "              f\"-> {compaction_result['compacted_msgs']} msgs ({compaction_result['compacted_tokens']} tokens) ***\")\n",
    "    \n",
    "    print(f\"\\n  SENT TO AGENT ({len(sent_to_agent)} messages, {compactor.count_tokens(sent_to_agent)} tokens):\")\n",
    "    show_messages(sent_to_agent)\n",
    "    \n",
    "    # 2. NEW MESSAGES (response from this turn)\n",
    "    new_msgs = list(result.new_messages())\n",
    "    print(f\"\\n  NEW MESSAGES ({len(new_msgs)} messages, {compactor.count_tokens(new_msgs)} tokens):\")\n",
    "    show_messages(new_msgs)\n",
    "    \n",
    "    # 3. Accumulate to uncompressed history\n",
    "    if message_history is None:\n",
    "        message_history = new_msgs\n",
    "    else:\n",
    "        message_history = message_history + new_msgs\n",
    "    \n",
    "    print(f\"\\n  UNCOMPRESSED HISTORY ({len(message_history)} messages, {compactor.count_tokens(message_history)} tokens):\")\n",
    "    show_messages(message_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
