{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935800cf",
   "metadata": {},
   "source": [
    "# RAG 02: Decomposing the retrieval process\n",
    "\n",
    "This example demonstrates query expansion and multi-step retrieval using pydantic-ai embeddings and Chroma.\n",
    "Uses the LLM-chunked collection from example_RAG_02_load.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef54532",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f859f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_patterns.core.agents import get_agent, run_agent\n",
    "from agentic_patterns.core.vectordb import get_vector_db, vdb_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af9767",
   "metadata": {},
   "source": [
    "## Vector-db: Load existing collection\n",
    "\n",
    "Assumes the 'books_llm_chunked' collection was populated by running example_RAG_02_load.ipynb first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9dc224",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdb = get_vector_db(\"books_llm_chunked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check database has documents\n",
    "count = vdb.count()\n",
    "assert count > 0, (\n",
    "    \"Vector database is empty, please run example_RAG_02_load.ipynb first to populate it.\"\n",
    ")\n",
    "print(f\"Collection has {count} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a0484",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecd004",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is a man with two heads?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f00bea6",
   "metadata": {},
   "source": [
    "### Query expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf68fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Given the following user query, reformulate the query in three to five different ways to retrieve relevant documents from the vector database.\n",
    "\n",
    "{query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40649b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = get_agent(output_type=list[str])  # type: ignore\n",
    "agent_run, nodes = await run_agent(agent, prompt=prompt, verbose=True)\n",
    "\n",
    "assert agent_run is not None and agent_run.result is not None\n",
    "reformulated_queries = agent_run.result.output\n",
    "\n",
    "print(f\"\\nAnswer (len {len(reformulated_queries)}):\")\n",
    "for i, query in enumerate(reformulated_queries):\n",
    "    print(f\"{i + 1:2d}: {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25ddfc",
   "metadata": {},
   "source": [
    "### Query vector database with metadata filtering\n",
    "\n",
    "The `vdb_query` function supports a `filter` parameter for metadata constraints. Filtering at the database level is more efficient than post-retrieval filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metadata filter - only retrieve documents from this book\n",
    "book_name = \"hhgttg\"\n",
    "metadata_filter = {\"source\": book_name}\n",
    "\n",
    "# Query with each reformulated query, applying the filter\n",
    "documents_with_scores = []\n",
    "for q in reformulated_queries:\n",
    "    print(f\"Query: {q}\")\n",
    "    documents_with_scores.extend(vdb_query(vdb, query=q, filter=metadata_filter))\n",
    "\n",
    "print(f\"\\nFound {len(documents_with_scores)} documents from '{book_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea3e2d",
   "metadata": {},
   "source": [
    "### Deduplication\n",
    "\n",
    "Query expansion retrieves documents for each reformulated query. The same document may appear multiple times if it matches several variations. Deduplication removes these duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637efa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate by creating a unique key from source and chunk\n",
    "seen_ids = set()\n",
    "documents_deduplicated = []\n",
    "for doc, meta, score in documents_with_scores:\n",
    "    doc_id = f\"{meta['source']}-{meta['chunk']}\"\n",
    "    if doc_id in seen_ids:\n",
    "        continue\n",
    "    documents_deduplicated.append((doc, meta, score, doc_id))\n",
    "    seen_ids.add(doc_id)\n",
    "print(f\"Deduplicated to {len(documents_deduplicated)} unique documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cfdc3a",
   "metadata": {},
   "source": [
    "### Sorting and limiting\n",
    "\n",
    "Sort by similarity score and limit the number of results. In production systems, this step could use a cross-encoder model that jointly encodes query-document pairs for more accurate relevance scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66417213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by score (index 2) and limit results\n",
    "documents_sorted = sorted(documents_deduplicated, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "max_results = 10\n",
    "if len(documents_sorted) > max_results:\n",
    "    documents_sorted = documents_sorted[:max_results]\n",
    "\n",
    "print(f\"Top {len(documents_sorted)} documents by similarity score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f71741",
   "metadata": {},
   "source": [
    "### Add results to prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_str = \"\"\n",
    "for doc, meta, score, doc_id in documents_sorted:\n",
    "    docs_str += (\n",
    "        f\"Similarity Score: {score:.3f}\\nDocument ID: {doc_id}\\nDocument:\\n{doc}\\n\\n\"\n",
    "    )\n",
    "    text = doc.replace(\"\\n\", \" \")\n",
    "    print(f\"Score: {score:.3f}, ID: {doc_id}, Document: {text[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cb7263",
   "metadata": {},
   "source": [
    "### Prompt: Grounding on retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ae066",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Given the following documents, answer the user's question.\n",
    "Show used references (using document ids).\n",
    "\n",
    "## Documents\n",
    "\n",
    "{docs_str}\n",
    "\n",
    "## User's question\n",
    "\n",
    "{query}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(prompt[:1000])  # Print the first 1000 characters of the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c4346",
   "metadata": {},
   "source": [
    "### Query the LLM with the vdb resuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = get_agent()\n",
    "agent_run, nodes = await run_agent(agent, prompt=prompt, verbose=True)\n",
    "\n",
    "assert agent_run is not None and agent_run.result is not None\n",
    "answer = agent_run.result.output\n",
    "print(f\"\\nAnswer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_agentic_patterns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
