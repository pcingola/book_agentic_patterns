{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Doctors: AI-Powered Quality Analysis\n",
    "\n",
    "Doctors analyze AI artifacts (prompts, tools, MCP servers, agent cards) and provide recommendations.\n",
    "They use an LLM to evaluate quality, clarity, and completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_patterns.core.doctors.prompt_doctor import PromptDoctor\n",
    "from agentic_patterns.core.doctors.tool_doctor import ToolDoctor\n",
    "from agentic_patterns.core.doctors.mcp_doctor import MCPDoctor\n",
    "from agentic_patterns.core.doctors.a2a_doctor import A2ADoctor\n",
    "from pydantic_ai.mcp import MCPServerStdio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-doctor-section",
   "metadata": {},
   "source": [
    "## PromptDoctor: Analyzing Prompts\n",
    "\n",
    "PromptDoctor evaluates prompt templates for clarity, completeness, and potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-doctor-bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A poorly written prompt\n",
    "bad_prompt = \"do the thing with {x}\"\n",
    "\n",
    "doctor = PromptDoctor()\n",
    "result = await doctor.analyze(bad_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-doctor-good",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A well-written prompt\n",
    "good_prompt = \"\"\"You are a technical writer. Summarize the following document in 3 bullet points.\n",
    "\n",
    "Document:\n",
    "{document}\n",
    "\n",
    "Respond with exactly 3 bullet points, each starting with a dash.\"\"\"\n",
    "\n",
    "result = await doctor.analyze(good_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tool-doctor-section",
   "metadata": {},
   "source": [
    "## ToolDoctor: Analyzing Tool Functions\n",
    "\n",
    "ToolDoctor evaluates tool definitions for proper naming, documentation, and type hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-doctor-bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A poorly defined tool\n",
    "def do_stuff(x):\n",
    "    \"\"\"Does stuff.\"\"\"\n",
    "    return x\n",
    "\n",
    "doctor = ToolDoctor()\n",
    "result = await doctor.analyze(do_stuff)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-doctor-good",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A well-defined tool\n",
    "def search_database(query: str, limit: int = 10) -> list[dict]:\n",
    "    \"\"\"Search the database for records matching the query.\n",
    "    \n",
    "    Returns a list of matching records, each containing 'id', 'name', and 'score' fields.\n",
    "    \"\"\"\n",
    "    return []\n",
    "\n",
    "result = await doctor.analyze(search_database)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-doctor-section",
   "metadata": {},
   "source": [
    "## MCPDoctor: Analyzing MCP Server Tools\n",
    "\n",
    "MCPDoctor connects to an MCP server and analyzes all its exposed tools.\n",
    "We have two example servers: `mcp_server_bad.py` (poorly defined) and `mcp_server_good.py` (well defined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mcp-doctor-bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the poorly defined MCP server\n",
    "mcp_server = MCPServerStdio(command=\"fastmcp\", args=[\"run\", \"-t\", \"stdio\", \"mcp_server_bad.py\"])\n",
    "\n",
    "doctor = MCPDoctor(mcp_server)\n",
    "results = await doctor.analyze_all()\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mcp-doctor-good",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the well-defined MCP server\n",
    "mcp_server = MCPServerStdio(command=\"fastmcp\", args=[\"run\", \"-t\", \"stdio\", \"mcp_server_good.py\"])\n",
    "\n",
    "doctor = MCPDoctor(mcp_server)\n",
    "results = await doctor.analyze_all()\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a-doctor-section",
   "metadata": {},
   "source": [
    "## A2ADoctor: Analyzing Agent Cards\n",
    "\n",
    "A2ADoctor connects to A2A servers and analyzes their agent cards.\n",
    "\n",
    "Start the servers in separate terminals:\n",
    "\n",
    "```bash\n",
    "# In termina 1\n",
    "cd agentic_patterns/examples/evals\n",
    "uvicorn a2a_server_bad:app --port 8001\n",
    "\n",
    "# In termina 2\n",
    "cd agentic_patterns/examples/evals\n",
    "uvicorn a2a_server_good:app --port 8002\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a-doctor-bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the poorly defined A2A server\n",
    "doctor = A2ADoctor()\n",
    "result = await doctor.analyze(\"http://127.0.0.1:8001\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a-doctor-good",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the well-defined A2A server\n",
    "result = await doctor.analyze(\"http://127.0.0.1:8002\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71307cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
