{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94bcc262",
   "metadata": {},
   "source": [
    "# Basic Evals\n",
    "\n",
    "Evals turn \"this agent seems to work\" into repeatable, versioned evidence about correctness.\n",
    "This notebook demonstrates three evaluation approaches: exact matching, structured outputs, and LLM-as-a-Judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_patterns.core.agents import get_agent, run_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2758f",
   "metadata": {},
   "source": [
    "## String Matching Eval\n",
    "\n",
    "The simplest eval: check if the response contains the expected answer.\n",
    "Works for factual questions with known answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863472d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_simple_eval():\n",
    "    agent = get_agent()\n",
    "    prompt = \"What's the capital of Nepal?\"\n",
    "    agent_run, _ = await run_agent(agent, prompt)\n",
    "    answer = agent_run.result.output\n",
    "    print(f\"Agent's answer: {answer}\")\n",
    "    # Check if the response contains the expected answer\n",
    "    assert 'kathmandu' in answer.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "await test_simple_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69326062",
   "metadata": {},
   "source": [
    "## Structured Output Eval\n",
    "\n",
    "Structured outputs (bool, int, enum) make assertions trivial.\n",
    "The model returns a typed value instead of free-form text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6286858",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_simple_eval_structured():\n",
    "    agent = get_agent(output_type=bool)\n",
    "    prompt = \"Is the capital of Nepal Kathmandu?\"\n",
    "    agent_run, _ = await run_agent(agent, prompt)\n",
    "    answer = agent_run.result.output\n",
    "    print(f\"Agent's answer: {answer}\")\n",
    "    assert answer is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2384577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await test_simple_eval_structured()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ce385",
   "metadata": {},
   "source": [
    "## LLM-as-a-Judge\n",
    "\n",
    "For open-ended questions without exact answers, use another LLM to evaluate.\n",
    "The judge assesses whether the answer correctly addresses the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe15064",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def judge(question: str, answer: str) -> None:\n",
    "    \"\"\"Judge if the answer is correct for the given question.\"\"\"\n",
    "    judge_agent = get_agent(output_type=bool)\n",
    "    judge_prompt = f\"\"\"\n",
    "# Judge\n",
    "\n",
    "Given a question, judge if the following answer is correct.\n",
    "\n",
    "## Question\n",
    "\n",
    "{question}\n",
    "\n",
    "## Answer\n",
    "\n",
    "{answer}\n",
    "\"\"\"\n",
    "    agent_run, _ = await run_agent(judge_agent, judge_prompt)\n",
    "    is_correct = agent_run.result.output\n",
    "    print(f\"Judge verdict: {is_correct}\")\n",
    "    assert is_correct is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_llm_as_a_judge():\n",
    "    agent = get_agent()\n",
    "    question = \"Why is the sky blue?\"\n",
    "    agent_run, _ = await run_agent(agent, question)\n",
    "    answer = agent_run.result.output\n",
    "    print(f\"Agent's answer: {answer}\")\n",
    "    await judge(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "await test_llm_as_a_judge()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_agentic_patterns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
