{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935800cf",
   "metadata": {},
   "source": [
    "# RAG 02: Decomposing the retrieval process\n",
    "\n",
    "This example demonstrates query expansion and multi-step retrieval using pydantic-ai embeddings and Chroma.\n",
    "Uses the LLM-chunked collection from example_RAG_02_load.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef54532",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f859f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from agentic_patterns.core.agents import get_agent, run_agent\n",
    "from agentic_patterns.core.vectordb import get_vector_db, vdb_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af9767",
   "metadata": {},
   "source": [
    "## Vector-db: Load existing collection\n",
    "\n",
    "Assumes the 'books_llm_chunked' collection was populated by running example_RAG_02_load.ipynb first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9dc224",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdb = get_vector_db('books_llm_chunked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check database has documents\n",
    "count = vdb.count()\n",
    "assert count > 0, \"Vector database is empty, please run example_RAG_02_load.ipynb first to populate it.\"\n",
    "print(f\"Collection has {count} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a0484",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecd004",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is a man with two heads?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f00bea6",
   "metadata": {},
   "source": [
    "### Query expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf68fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Given the following user query, reformulate the query in three to five different ways to retrieve relevant documents from the vector database.\n",
    "\n",
    "{query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40649b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = get_agent(output_type=list[str]) # type: ignore\n",
    "reformulated_queries, nodes = await run_agent(agent, prompt=prompt, verbose=True)\n",
    "\n",
    "\n",
    "print(f\"\\nAnswer (len {len(reformulated_queries)}):\")\n",
    "for i, query in enumerate(reformulated_queries):\n",
    "    print(f\"{i+1:2d}: {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25ddfc",
   "metadata": {},
   "source": [
    "### Query vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_with_scores = []\n",
    "for query in reformulated_queries:\n",
    "    print(f\"Query: {query}\")\n",
    "    # Query the vector database - returns (doc, meta, score) tuples\n",
    "    documents_with_scores.extend(vdb_query(vdb, query=query))\n",
    "\n",
    "print(f\"\\nFound {len(documents_with_scores)} documents with scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea3e2d",
   "metadata": {},
   "source": [
    "### Filter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637efa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate by creating a unique key from source and chunk\n",
    "seen_ids = set()\n",
    "documents_with_scores_filtered = []\n",
    "for doc, meta, score in documents_with_scores:\n",
    "    doc_id = f\"{meta['source']}-{meta['chunk']}\"\n",
    "    if doc_id in seen_ids:\n",
    "        continue\n",
    "    documents_with_scores_filtered.append((doc, meta, score, doc_id))\n",
    "    seen_ids.add(doc_id)\n",
    "print(f\"Filtered to {len(documents_with_scores_filtered)} unique documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac4969",
   "metadata": {},
   "source": [
    "### Metadata filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name = 'hhgttg'\n",
    "documents_with_scores_filtered_meta = []\n",
    "for doc, meta, score, doc_id in documents_with_scores_filtered:\n",
    "    if book_name in meta['source']:\n",
    "        documents_with_scores_filtered_meta.append((doc, meta, score, doc_id))\n",
    "print(f\"Filtered to {len(documents_with_scores_filtered_meta)} documents from '{book_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cfdc3a",
   "metadata": {},
   "source": [
    "### Re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66417213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trivial \"re-ranking\" by score (index 2 is the score)\n",
    "documents_with_scores_reranked = sorted(documents_with_scores_filtered_meta, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "max_results = 10\n",
    "if len(documents_with_scores_reranked) > max_results:\n",
    "    documents_with_scores_reranked = documents_with_scores_reranked[:max_results]\n",
    "\n",
    "print(f\"Re-ranked to top {len(documents_with_scores_reranked)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f71741",
   "metadata": {},
   "source": [
    "### Add results to prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_str = ''\n",
    "for doc, meta, score, doc_id in documents_with_scores_reranked:\n",
    "    docs_str += f\"Similarity Score: {score:.3f}\\nDocument ID: {doc_id}\\nDocument:\\n{doc}\\n\\n\"\n",
    "    text = doc.replace('\\n', ' ')\n",
    "    print(f\"Score: {score:.3f}, ID: {doc_id}, Document: {text[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cb7263",
   "metadata": {},
   "source": [
    "### Prompt: Grounding on retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ae066",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Given the following documents, answer the user's question.\n",
    "Show used references (using document ids).\n",
    "\n",
    "## Documents\n",
    "\n",
    "{docs_str}\n",
    "\n",
    "## User's question\n",
    "\n",
    "{query}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(prompt[:1000])  # Print the first 1000 characters of the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c4346",
   "metadata": {},
   "source": [
    "### Query the LLM with the vdb resuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = get_agent()\n",
    "answer, nodes = await run_agent(agent, prompt=prompt, verbose=True)\n",
    "print(f\"\\nAnswer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
